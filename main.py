"""
ä¸»å…¥å£ - Gelbooru å›¾ç‰‡ä¸‹è½½å™¨
ä½¿ç”¨æ–¹æ³•: python main.py [æ¨¡å¼]

æ¶æ„è¯´æ˜:
- ä¸»çº¿ç¨‹è´Ÿè´£æ‰€æœ‰æ–‡ä»¶å†™å…¥æ“ä½œ
- å·¥ä½œçº¿ç¨‹åªè´Ÿè´£ä¸‹è½½å’Œæ”¶é›†æ•°æ®
- é€šè¿‡è¿”å›JSONæ•°æ®é¿å…å¹¶å‘å†²çª
- ç¼©ç•¥å›¾ç”Ÿæˆä½¿ç”¨ç‹¬ç«‹å•çº¿ç¨‹æ± å¼‚æ­¥å¤„ç†
"""
import sys
import os
import time
import queue
import concurrent.futures
from core import (
    Regex, LoggerManager, WebClient, DatabaseManager, format_size, load_tag_mapping
)
import datetime
import glob
from operator import itemgetter
import set_tag
from set_tag import writefile, readfile
import sampletag
from downloader import down_single, down_batch_mode3_queue, set_sample_executor
from core import config, get_database, load_tag_mapping

# å…¨å±€ç¼©ç•¥å›¾çº¿ç¨‹æ± ï¼ˆå•çº¿ç¨‹ï¼Œé¿å…PILå¹¶å‘é—®é¢˜ï¼‰
sample_executor = concurrent.futures.ThreadPoolExecutor(max_workers=1, thread_name_prefix='sample')

# è®¾ç½®åˆ°downloaderæ¨¡å—
set_sample_executor(sample_executor)


def write_failed_records(failed_records):
    """å†™å…¥å¤±è´¥è®°å½•"""
    if not failed_records:
        return
    
    with open(config['path']['failed'], 'a', encoding='utf-8') as f:
        for record in failed_records:
            f.write(f"{record['tag']}|{record['url']}|{record['time']}|"
                   f"{record['id']}|{record['filename']}|{record['tags']}\n")


def write_tag_time(tag_time_dict):
    """
    å†™å…¥downtagæ–‡ä»¶ï¼ˆæ”¯æŒ4ä¸ªå†å²æ—¶é—´æˆ³ï¼‰
    
    æ–°æ ¼å¼: tag {num}: {tag} |time1: {time}|time2: {time}|time3: {time}|time4: {time}
    - time1: æœ€æ–°çš„ä¸‹è½½æ—¶é—´
    - time2-4: å†å²ä¸‹è½½æ—¶é—´ï¼ˆä¾æ¬¡å‘åæ¨ç§»ï¼‰
    - å¦‚æœæ–°çš„time1å’Œå½“å‰time1ç›¸åŒï¼Œä¸æ›´æ–°
    - æŒ‰time1å€’åºæ’åˆ—ï¼ˆæœ€æ–°åœ¨æœ€ä¸‹ï¼Œnumberæœ€å°ï¼‰
    - ä½¿ç”¨ tag-replace.txt å°† replace_tag è½¬æ¢ä¸º original_tag
    """
    if not tag_time_dict:
        return
    
    file_path = config['path']['downtag']
    DEFAULT_TIME = '2000-01-01 00:00:00'
    
    # åŠ è½½ tag æ˜ å°„å…³ç³»ï¼ˆreplace_tag -> original_tagï¼‰
    tag_mapping = load_tag_mapping(reverse=True)
    
    # è½¬æ¢ tag_time_dict ä¸­çš„ replace_tag ä¸º original_tag
    normalized_tag_time = {}
    for tag, time_val in tag_time_dict.items():
        # å¦‚æœæ˜¯ replace_tagï¼Œè½¬æ¢ä¸º original_tag
        original_tag = tag_mapping.get(tag, tag)
        normalized_tag_time[original_tag] = time_val
    
    # è¯»å–ç°æœ‰æ•°æ®ï¼ˆæ”¯æŒæ–°æ—§ä¸¤ç§æ ¼å¼ï¼‰
    tag_times = {}  # {tag_name: [time1, time2, time3, time4]}
    
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if not line or 'time' not in line:
                    continue
                
                # è§£ætagå
                if ': ' not in line:
                    continue
                parts = line.split(': ', 1)
                if len(parts) != 2:
                    continue
 # è§£ææ—¶é—´ï¼ˆæ”¯æŒæ–°æ—§æ ¼å¼ï¼‰
                if '|time1:' in line:
                    # æ–°æ ¼å¼: |time1: xxx|time2: xxx|time3: xxx|time4: xxx
                    # ä¸€æ¬¡æ€§è§£æå®Œæˆ
                    tag_name = parts[1].split('|')[0].strip()
                    time_parts = line.split('|')
                    times = []
                    for part in time_parts:
                        if 'time' in part and ':' in part:
                            time_str = part.split(':', 1)[1].strip()
                            if len(time_str) == 19:  # YYYY-MM-DD HH:MM:SS
                                times.append(time_str)
                    # è¡¥é½åˆ°4ä¸ªæ—¶é—´æˆ³
                    times = (times + [DEFAULT_TIME] * 4)[:4]
                    tag_times[tag_name] = times
                
                elif 'time:' in line:
                    # æ—§æ ¼å¼: time: xxx
                    time_str = line.split('time:', 1)[1].strip()
                    tag_name = parts[1].split('time:')[0].strip()
                    tag_times[tag_name] = [time_str, DEFAULT_TIME, DEFAULT_TIME, DEFAULT_TIME]
    except FileNotFoundError:
        pass  # æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨ç©ºå­—å…¸
    
    # æ›´æ–°æ–°çš„æ—¶é—´
    def parse_time(time_str):
        return datetime.datetime.strptime(time_str, "%Y-%m-%d %H:%M:%S")
    
    for tag, new_time in normalized_tag_time.items():
        if tag not in tag_times:
            # æ–°tagï¼Œåˆå§‹åŒ–
            tag_times[tag] = [new_time, DEFAULT_TIME, DEFAULT_TIME, DEFAULT_TIME]
        else:
            current_times = tag_times[tag]
            # å¦‚æœæ–°æ—¶é—´å’Œtime1ç›¸åŒï¼Œä¸æ›´æ–°
            if new_time != current_times[0]:
                # æ–°æ—¶é—´ä¸åŒï¼Œå‘åæ¨ç§»
                tag_times[tag] = [
                    new_time,           # time1: æ–°æ—¶é—´
                    current_times[0],   # time2: åŸtime1
                    current_times[1],   # time3: åŸtime2
                    current_times[2]    # time4: åŸtime3ï¼ˆåŸtime4ä¸¢å¼ƒï¼‰
                ]
    
    # æŒ‰time1æ’åºï¼ˆå€’åºï¼Œæœ€æ–°åœ¨æœ€ä¸‹ï¼‰
    entries = []
    for tag, times in tag_times.items():
        time1_dt = parse_time(times[0])
        entries.append((tag, time1_dt, times))
    
    entries.sort(key=itemgetter(1), reverse=False)
    
    # å†™å…¥æ–°æ ¼å¼
    content = []
    for idx, (tag, _, times) in enumerate(entries, 1):
        entry_id = len(entries) - idx + 1
        time_str = f"|time1: {times[0]}|time2: {times[1]}|time3: {times[2]}|time4: {times[3]}"
        line = f"tag {entry_id:4}: {tag.ljust(50)} {time_str}\n"
        content.append(line)
    
    with open(file_path, 'w') as f:
        f.writelines(content)



def print_summary_statistics(total_downloaded, total_failed, total_size):
    """
    æ‰“å°æ±‡æ€»ç»Ÿè®¡ä¿¡æ¯
    
    Args:
        total_downloaded: æ€»ä¸‹è½½æˆåŠŸæ•°
        total_failed: æ€»å¤±è´¥æ•°
        total_size: æ€»ä¸‹è½½å¤§å°ï¼ˆå­—èŠ‚ï¼‰
    """
    if total_downloaded == 0 and total_failed == 0:
        print("\n=== æ±‡æ€»ç»Ÿè®¡ ===")
        print("æœ¬æ¬¡è¿è¡Œæœªä¸‹è½½æ–°å›¾ç‰‡")
        return
    
    print("\n" + "="*50)
    print("           æ±‡æ€»ç»Ÿè®¡")
    print("="*50)
    
    # è®¡ç®—æ€»å¤§å°å’Œå¹³å‡å¤§å°
    if total_size > 0:
        if total_size < 1024 * 1024:
            # å°äº1MBï¼Œç”¨KBæ˜¾ç¤º
            total_size_str = f"{total_size / 1024:.2f} Kb"
            avg_size_str = f"{total_size / total_downloaded / 1024:.2f} Kb" if total_downloaded > 0 else "0 Kb"
        elif total_size < 1024 * 1024 * 1024:
            # å°äº1GBï¼Œç”¨MBæ˜¾ç¤º
            total_size_str = f"{total_size / 1024 / 1024:.2f} Mb"
            avg_size_str = f"{total_size / total_downloaded / 1024 / 1024:.2f} Mb" if total_downloaded > 0 else "0 Mb"
        else:
            # å¤§äº1GBï¼Œç”¨GBæ˜¾ç¤º
            total_size_str = f"{total_size / 1024 / 1024 / 1024:.2f} Gb"
            avg_size_str = f"{total_size / total_downloaded / 1024 / 1024:.2f} Mb" if total_downloaded > 0 else "0 Mb"
        
        print(f"Total size: {total_size_str}  avg size: {avg_size_str}")
    
    print(f"Total download: {total_downloaded} failed: {total_failed}")
    
    if total_downloaded > 0:
        success_rate = (total_downloaded / (total_downloaded + total_failed)) * 100
        print(f"Success rate: {success_rate:.1f}%")
    
    print("="*50 + "\n")


def handle_result(result):
    """
    å¤„ç†å•ä¸ªä¸‹è½½å™¨è¿”å›çš„ç»“æœï¼Œç»Ÿä¸€å†™å…¥æ–‡ä»¶
    
    æ³¨æ„: æ—¥å¿—å’ŒGelbooru/{tag}/tags.txtå·²ç”±çº¿ç¨‹å®æ—¶å†™å…¥ï¼ˆå„è‡ªç‹¬ç«‹æ–‡ä»¶ï¼Œæ— å†²çªï¼‰
    
    Args:
        result: Downloaderè¿”å›çš„å­—å…¸
    """
    # 1. å†™å…¥å¤±è´¥è®°å½•
    if result.get('failed_records'):
        write_failed_records(result['failed_records'])
    
    # 2. ä¸‹è½½å®Œæˆï¼Œåˆ é™¤æ•°æ®åº“è®°å½•
    if result.get('delete_tag'):
        set_tag.delete_tagjson(result['tag'])
    
    # 3. è®¾ç½®ä¸ºå®Œæˆ
    if result.get('set_input_done'):
        set_tag.set_input_done(result['set_input_done'])
    
    # 6. åˆ é™¤å¯åŠ¨æ–‡ä»¶
    if result.get('remove_startfile') and os.path.exists(result.get('remove_startfile')):
        os.remove(result['remove_startfile'])
    
    # 7. æ·»åŠ è¿‡æœŸtag
    if result.get('expire_tags'):
        for expire_tag in result['expire_tags']:
            set_tag.add_expire_tag(expire_tag)
    
    # æ³¨æ„ï¼šç¼©ç•¥å›¾å·²åœ¨downloaderä¸­å¼‚æ­¥æäº¤ï¼Œæ­¤å¤„æ— éœ€å¤„ç†

def _run_download_mode(status_filter, mode_name):
    """
    é€šç”¨ä¸‹è½½æ¨¡å¼ï¼ˆmode 1/2 å…¬å…±é€»è¾‘ï¼‰
    
    Args:
        status_filter: çŠ¶æ€è¿‡æ»¤å™¨ï¼ˆlistï¼‰
        mode_name: æ¨¡å¼åç§°ï¼ˆç”¨äºæ—¥å¿—ï¼‰
    """
    from core import get_database
    
    try:
        # åˆå§‹åŒ–
        set_tag.add_folder_tag()
        set_tag.init_input()
        
        tags_config = set_tag.read_tagjson()
        
        # ç­›é€‰ä»»åŠ¡
        tasks = [(tag, info) for tag, info in tags_config.items() 
                 if info['status'] in status_filter]
        
        if not tasks:
            print(f"æ²¡æœ‰éœ€è¦{mode_name}çš„æ ‡ç­¾")
            return
        
        print(f"å‡†å¤‡{mode_name} {len(tasks)} ä¸ªæ ‡ç­¾")
        
        # ä½¿ç”¨6çº¿ç¨‹å¹¶å‘ä¸‹è½½
        with concurrent.futures.ThreadPoolExecutor(max_workers=6) as executor:
            futures = {executor.submit(down_single, tag, tag_config): tag 
                      for tag, tag_config in tasks}
            
            # æ”¶é›†æ‰€æœ‰ç»“æœ
            all_tag_time = {}
            total_downloaded = 0
            total_failed = 0
            total_size = 0
            
            for future in concurrent.futures.as_completed(futures):
                tag = futures[future]
                try:
                    result = future.result()
                    
                    # ç»Ÿä¸€å¤„ç†ç»“æœï¼ˆä¸»çº¿ç¨‹å†™å…¥ï¼‰
                    handle_result(result)
                    
                    # åˆå¹¶tag_time
                    if result.get('tag_time'):
                        all_tag_time.update(result['tag_time'])
                    
                    # æ”¶é›†ç»Ÿè®¡æ•°æ®
                    stats = result.get('statistics', {})
                    total_downloaded += stats.get('downloaded', 0)
                    total_failed += stats.get('failed', 0)
                    total_size += stats.get('total_size', 0)
                    
                    print(f"âœ“ {tag} å®Œæˆ")
                except Exception as e:
                    print(f"âœ— {tag} å‡ºé”™: {e}")
            
            # æœ€åç»Ÿä¸€å†™å…¥tag_time
            if all_tag_time:
                write_tag_time(all_tag_time)
            
            # æ‰“å°æ±‡æ€»ç»Ÿè®¡
            print_summary_statistics(total_downloaded, total_failed, total_size)
    
    finally:
        # å…³é—­æ•°æ®åº“è¿æ¥
        try:
            get_database().close_all_connections()
        except Exception as e:
            print(f"âš ï¸  å…³é—­æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")


def mode_1():
    """
    æ¨¡å¼1: ä¸‹è½½æ–°æ ‡ç­¾ï¼ˆæ”¯æŒåŠ¨æ€æ·»åŠ  + è‡ªåŠ¨æ¢å¤ä¸­æ–­ï¼‰
    
    ç‰¹ç‚¹ï¼š
    - ä¸‹è½½ status=0ï¼ˆæ–°tagï¼‰å’Œ status=1ï¼ˆä¸­æ–­çš„tagï¼‰
    - å¼‚å¸¸ä¸­æ–­åè‡ªåŠ¨æ¢å¤ï¼Œæ— éœ€æ‰‹åŠ¨åˆ‡æ¢æ¨¡å¼
    - æ¯å®Œæˆä¸€ä¸ªtagåç«‹å³æ ‡è®°done
    - åŠ¨æ€æ‰«æinput.txtï¼Œå®æ—¶æ·»åŠ æ–°tag
    - è‡ªåŠ¨æ¸…ç†å­¤ç«‹çš„ .start æ–‡ä»¶
    """
    from core import get_database
    import os
    import glob
    
    try:
        # åˆå§‹åŒ–
        set_tag.add_folder_tag()
        set_tag.init_input()
        
        tags_config = set_tag.read_tagjson()
        
        # æ¸…ç†å­¤ç«‹çš„ .start æ–‡ä»¶
        new_path = config['path']['new']
        start_files = glob.glob(os.path.join(new_path, '*.start'))
        
        if start_files:
            # è·å–æ‰€æœ‰æ´»è·ƒçš„ tagï¼ˆè½¬æ¢ä¸ºæ–‡ä»¶åæ ¼å¼ï¼‰
            active_tags = set()
            for tag in tags_config.keys():
                replace_tag = tag.replace('/', '_').replace('\\', '_')
                active_tags.add(f'zzz{replace_tag}.start')
                active_tags.add(f'{tag}.start')
                active_tags.add(f'zzztag{replace_tag}.start')
            
            # æ¸…ç†ä¸å±äºæ´»è·ƒ tag çš„ .start æ–‡ä»¶
            cleaned = 0
            for start_file in start_files:
                basename = os.path.basename(start_file)
                if basename not in active_tags:
                    try:
                        os.remove(start_file)
                        cleaned += 1
                    except Exception as e:
                        print(f"âš ï¸  æ¸…ç†å¯åŠ¨æ–‡ä»¶å¤±è´¥ {basename}: {e}")
            
            if cleaned > 0:
                print(f"âœ“ æ¸…ç†äº† {cleaned} ä¸ªå­¤ç«‹çš„å¯åŠ¨æ–‡ä»¶")
        
        # ç­›é€‰åˆå§‹ä»»åŠ¡ï¼ˆstatus=0 æ–°tag + status=1 ä¸­æ–­tagï¼‰
        initial_tasks = [(tag, info) for tag, info in tags_config.items() 
                        if info['status'] in [0, 1]]
        
        if not initial_tasks:
            print("æ²¡æœ‰éœ€è¦ä¸‹è½½çš„æ ‡ç­¾")
            return
        
        # ç»Ÿè®¡æ–°tagå’Œä¸­æ–­tag
        new_count = sum(1 for _, info in initial_tasks if info['status'] == 0)
        interrupted_count = sum(1 for _, info in initial_tasks if info['status'] == 1)
        
        if interrupted_count > 0:
            print(f"å¼€å§‹ä¸‹è½½ {len(initial_tasks)} ä¸ªæ ‡ç­¾ï¼ˆ{new_count} ä¸ªæ–°æ ‡ç­¾ + {interrupted_count} ä¸ªæ¢å¤ä¸­æ–­ï¼‰")
        else:
            print(f"å¼€å§‹ä¸‹è½½ {new_count} ä¸ªæ–°æ ‡ç­¾")
        
        # å·²å¤„ç†çš„tagé›†åˆï¼ˆé¿å…é‡å¤ï¼‰
        processed_tags = set()
        
        # åˆ›å»ºä»»åŠ¡é˜Ÿåˆ—
        task_queue = queue.Queue()
        for tag, tag_config in initial_tasks:
            task_queue.put((tag, tag_config))
            processed_tags.add(tag)
        
        # ç»Ÿè®¡æ•°æ®
        all_tag_time = {}
        total_downloaded = 0
        total_failed = 0
        total_size = 0
        completed_count = 0
        
        # ä½¿ç”¨6çº¿ç¨‹å¹¶å‘ä¸‹è½½
        with concurrent.futures.ThreadPoolExecutor(max_workers=6) as executor:
            active_futures = {}
            
            # æäº¤åˆå§‹ä»»åŠ¡ï¼ˆæœ€å¤š6ä¸ªï¼‰
            while not task_queue.empty() and len(active_futures) < 6:
                tag, tag_config = task_queue.get()
                future = executor.submit(down_single, tag, tag_config)
                active_futures[future] = tag
            
            # åŠ¨æ€å¤„ç†ä»»åŠ¡
            while active_futures:
                # ç­‰å¾…ä»»ä½•ä¸€ä¸ªä»»åŠ¡å®Œæˆï¼ˆè¶…æ—¶1ç§’ï¼‰
                done_futures = []
                try:
                    for future in concurrent.futures.as_completed(active_futures.keys(), timeout=1):
                        done_futures.append(future)
                except concurrent.futures.TimeoutError:
                    # è¶…æ—¶ï¼šæ²¡æœ‰ä»»åŠ¡å®Œæˆï¼Œç»§ç»­ç­‰å¾…ä¸‹ä¸€è½®
                    # ä½†ä»ç„¶æ£€æŸ¥æ–°tagï¼ˆæ¯ç§’æ‰«æä¸€æ¬¡ï¼‰
                    pass
                
                # å¤„ç†å®Œæˆçš„ä»»åŠ¡
                for future in done_futures:
                    tag = active_futures.pop(future)
                    completed_count += 1
                    
                    try:
                        result = future.result()
                        
                        # ç»Ÿä¸€å¤„ç†ç»“æœï¼ˆä¸»çº¿ç¨‹å†™å…¥ï¼‰
                        handle_result(result)
                        
                        # åˆå¹¶tag_time
                        if result.get('tag_time'):
                            all_tag_time.update(result['tag_time'])
                        
                        # æ”¶é›†ç»Ÿè®¡æ•°æ®
                        stats = result.get('statistics', {})
                        total_downloaded += stats.get('downloaded', 0)
                        total_failed += stats.get('failed', 0)
                        total_size += stats.get('total_size', 0)
                        
                        print(f"âœ“ [{completed_count}] {tag} å®Œæˆ")
                        
                        # ç«‹å³æ ‡è®°doneï¼ˆé¿å…ä¸‹æ¬¡é‡æ–°è¯»å–ï¼‰
                        if result.get('set_input_done'):
                            set_tag.set_input_done(result['set_input_done'])
                        
                    except Exception as e:
                        print(f"âœ— {tag} å‡ºé”™: {e}")
                
                # æ¯æ¬¡å¾ªç¯éƒ½æ£€æŸ¥æ–°tagï¼ˆä¸ç®¡æ˜¯å¦æœ‰ä»»åŠ¡å®Œæˆï¼‰
                new_tags = _scan_new_tags(processed_tags)
                for new_tag, new_config in new_tags:
                    task_queue.put((new_tag, new_config))
                    processed_tags.add(new_tag)
                    print(f"ğŸ†• å‘ç°æ–°æ ‡ç­¾: {new_tag}")
                
                # è¡¥å……æ–°ä»»åŠ¡åˆ°çº¿ç¨‹æ± ï¼ˆä¿æŒ6ä¸ªå¹¶å‘ï¼‰
                while not task_queue.empty() and len(active_futures) < 6:
                    tag, tag_config = task_queue.get()
                    future = executor.submit(down_single, tag, tag_config)
                    active_futures[future] = tag
            
            # æœ€åç»Ÿä¸€å†™å…¥tag_time
            if all_tag_time:
                write_tag_time(all_tag_time)
            
            # æ‰“å°æ±‡æ€»ç»Ÿè®¡
            print_summary_statistics(total_downloaded, total_failed, total_size)
    
    finally:
        # å…³é—­æ•°æ®åº“è¿æ¥
        try:
            get_database().close_all_connections()
        except Exception as e:
            print(f"âš ï¸  å…³é—­æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")


def _scan_new_tags(processed_tags):
    """
    æ‰«æinput.txtï¼ŒæŸ¥æ‰¾æ–°å¢çš„tag
    
    Args:
        processed_tags: å·²å¤„ç†çš„tagé›†åˆ
    
    Returns:
        list: [(tag, config), ...] æ–°tagåˆ—è¡¨
    """
    new_tags = []
    
    try:
        input_lines = set_tag.readfile(config['path']['input'])
        
        for line in input_lines:
            line = line.strip()
            if not line or line.startswith('TAG') or line.startswith('done '):
                continue
            
            # è§£ææ ‡ç­¾é…ç½®
            parts = line.split()
            if not parts:
                continue
            
            tag_name = parts[0]
            
            # è·³è¿‡å·²å¤„ç†çš„tag
            if tag_name in processed_tags:
                continue
            
            # è¡¥å…¨å‚æ•°ï¼štag [endpage] [start_pic] [end_pic]
            if len(parts) == 1:
                parts.extend(['1', '0', '0'])
            elif len(parts) == 2:
                parts.extend(['0', '0'])
            elif len(parts) == 3:
                parts.append('0')
            
            # æ„å»ºé…ç½®
            tag_config = {
                'startpage': 1,
                'endpage': int(parts[1]),
                'start_pic': int(parts[2]),
                'end_pic': str(parts[3]),
                'status': 0
            }
            
            # æ·»åŠ åˆ°æ•°æ®åº“
            db = get_database()
            db.init_tag_progress(
                tag=tag_name,
                endpage=tag_config['endpage'],
                start_pic=tag_config['start_pic'],
                end_pic=tag_config['end_pic'],
                status=0
            )
            
            new_tags.append((tag_name, tag_config))
    
    except Exception as e:
        print(f"æ‰«ææ–°æ ‡ç­¾å¤±è´¥: {e}")
    
    return new_tags


def mode_3():
    """æ¨¡å¼3: ä¸‹è½½æ‰€æœ‰æ—§æ ‡ç­¾ï¼ˆé˜Ÿåˆ—æ¨¡å¼ - åŠ¨æ€è´Ÿè½½å‡è¡¡ï¼‰"""
    
    try:
        print("\n=== Mode 3: Download All Old Tags ===\n")
        
        # 1. åˆå§‹åŒ–æ ‡ç­¾åˆ—è¡¨
        set_tag.add_folder_tag()
        set_tag.init_input(1)
        set_tag.add_dead_tag()
        taglist = set_tag.read_tags()
        
        if not taglist:
            print("æ²¡æœ‰å¯ä¸‹è½½çš„æ ‡ç­¾")
            return
        
        print(f"æ€»æ ‡ç­¾æ•°: {len(taglist)}")
        
        # 2. æ£€æŸ¥è¿è¡Œä¸­çš„ä»»åŠ¡
        end_files = glob.glob(os.path.join(config['path']['new'], "*.start"))
        running = len(end_files)
        workers = 6
        
        if running >= workers:
            print(f"å·²æœ‰{running}ä¸ªä»»åŠ¡è¿è¡Œä¸­ï¼Œæ— æ³•å¯åŠ¨æ–°ä»»åŠ¡")
            return
        
        # 3. è®¡ç®—å¯ç”¨çº¿ç¨‹æ•°
        available = workers - running
        print(f"è¿è¡Œä¸­ä»»åŠ¡: {running}, å¯ç”¨çº¿ç¨‹: {available}/{workers}")
        
        # 4. åˆ›å»ºä»»åŠ¡é˜Ÿåˆ—å¹¶å¡«å……
        task_queue = queue.Queue()
        for tag in taglist:
            task_queue.put(tag)
        
        # 5. æ·»åŠ ç»“æŸæ ‡è®°ï¼ˆæ¯ä¸ªçº¿ç¨‹ä¸€ä¸ªNoneï¼‰
        for _ in range(available):
            task_queue.put(None)
        
        print(f"ä»»åŠ¡é˜Ÿåˆ—å·²åˆ›å»º: {len(taglist)} ä¸ªtag\n")
        
        # 6. æ•°æ®æ”¶é›†å˜é‡
        all_tag_time = {}
        all_done_tags = []
        total_downloaded = 0
        total_failed = 0
        total_size = 0
        
        start_time = time.time()
        
        # 7. å¯åŠ¨å·¥ä½œçº¿ç¨‹
        with concurrent.futures.ThreadPoolExecutor(max_workers=available) as executor:
            futures = {executor.submit(down_batch_mode3_queue, task_queue, i+1): i+1 
                      for i in range(available)}
            
            # 8. æ”¶é›†ç»“æœ
            for future in concurrent.futures.as_completed(futures):
                offset = futures[future]
                try:
                    result = future.result()
                    
                    # ç»Ÿä¸€å¤„ç†ç»“æœ
                    handle_result(result)
                    
                    # åˆå¹¶æ•°æ®
                    if result.get('tag_time'):
                        all_tag_time.update(result['tag_time'])
                    
                    if result.get('done_tags'):
                        all_done_tags.extend(result['done_tags'])
                    
                    # æ”¶é›†ç»Ÿè®¡æ•°æ®
                    stats = result.get('statistics', {})
                    total_downloaded += stats.get('downloaded', 0)
                    total_failed += stats.get('failed', 0)
                    total_size += stats.get('total_size', 0)
                    
                    done_count = len(result.get('done_tags', []))
                    print(f"âœ“ çº¿ç¨‹{offset} å®Œæˆ: {done_count} ä¸ªtag")
                    
                except Exception as e:
                    print(f"âœ— çº¿ç¨‹{offset} å‡ºé”™: {e}")
        
        # 9. ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆ
        task_queue.join()
        
        elapsed_minutes = (time.time() - start_time) / 60
        
        # 10. ç»Ÿä¸€å†™å…¥ï¼ˆä¸»çº¿ç¨‹ï¼‰
        if all_tag_time:
            write_tag_time(all_tag_time)
            print(f"\nå·²æ›´æ–° {len(all_tag_time)} ä¸ªtagåˆ° downtag.txt")
        
        if all_done_tags:
            set_tag.add_tags(all_done_tags)
        print(f"å·²æ·»åŠ  {len(all_done_tags)} ä¸ªtagåˆ° tags.txt")
    
        # 11. è¾“å‡ºæ±‡æ€»ç»Ÿè®¡
        print(f"\n{'='*50}")
        print(f"  æ€»è€—æ—¶: {elapsed_minutes:.1f} åˆ†é’Ÿ")
        # è®¡ç®—ä¸‹è½½å¤§å°å­—ç¬¦ä¸²
        if total_size < 1024 * 1024:
            total_size_str = f"{total_size / 1024:.2f} KB"
        elif total_size < 1024 * 1024 * 1024:
            total_size_str = f"{total_size / 1024 / 1024:.2f} MB"
        else:
            total_size_str = f"{total_size / 1024 / 1024 / 1024:.2f} GB"
        print(f"  å·²å¤„ç†: {len(all_done_tags)}/{len(taglist)} ä¸ªtag ä¸‹è½½æ•°é‡ {total_downloaded} ä¸‹è½½å¤§å° {total_size_str}")
        print_summary_statistics(total_downloaded, total_failed, total_size)
        print(f"{'='*50}\n")
    
    finally:
        # å…³é—­æ•°æ®åº“è¿æ¥
        try:
            get_database().close_all_connections()
        except Exception as e:
            print(f"âš ï¸  å…³é—­æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")


def mode_4():
    """æ¨¡å¼4: æ¸…ç†å·²å®Œæˆè®°å½•"""
    set_tag.del_input_done()
    print("å·²å®Œæˆæ ‡ç­¾æ¸…ç†å®Œæ¯•")


def main():
    """ä¸»å‡½æ•°"""
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ–¹æ³•: python main.py [1|3|4]")
        print("  1 - ä¸‹è½½æ–°æ ‡ç­¾ï¼ˆè‡ªåŠ¨æ¢å¤ä¸­æ–­ï¼‰")
        print("  3 - ä¸‹è½½æ‰€æœ‰æ—§æ ‡ç­¾")
        print("  4 - æ¸…ç†å·²å®Œæˆè®°å½•")
        return
    
    mode = sys.argv[1]
    
    try:
        if mode == '1':
            mode_1()
        elif mode == '3':
            mode_3()
        elif mode == '4':
            mode_4()
        else:
            print(f"æœªçŸ¥æ¨¡å¼: {mode}")
            print("å¯ç”¨æ¨¡å¼: 1ï¼ˆæ–°æ ‡ç­¾+æ¢å¤ä¸­æ–­ï¼‰, 3ï¼ˆæ‰€æœ‰æ—§æ ‡ç­¾ï¼‰, 4ï¼ˆæ¸…ç†ï¼‰")
    finally:
        # ç­‰å¾…æ‰€æœ‰ç¼©ç•¥å›¾ä»»åŠ¡å®Œæˆ
        print("\nç­‰å¾…ç¼©ç•¥å›¾ç”Ÿæˆå®Œæˆ...")
        sample_executor.shutdown(wait=True)
        print("æ‰€æœ‰ä»»åŠ¡å®Œæˆ")


if __name__ == '__main__':
    main()

