"""
ä¸»å…¥å£ - Gelbooru å›¾ç‰‡ä¸‹è½½å™¨
ä½¿ç”¨æ–¹æ³•: python main.py [æ¨¡å¼]

æ¶æ„è¯´æ˜:
- ä¸»çº¿ç¨‹è´Ÿè´£æ‰€æœ‰æ–‡ä»¶å†™å…¥æ“ä½œ
- å·¥ä½œçº¿ç¨‹åªè´Ÿè´£ä¸‹è½½å’Œæ”¶é›†æ•°æ®
- é€šè¿‡è¿”å›JSONæ•°æ®é¿å…å¹¶å‘å†²çª
- ç¼©ç•¥å›¾ç”Ÿæˆåœ¨æ¯ä¸ªtagä¸‹è½½å®ŒæˆååŒæ­¥æ‰§è¡Œ
"""
import sys
import os
import time
import queue
import atexit
import concurrent.futures
import datetime
import glob
from operator import itemgetter
import set_tag
from downloader import down_single, down_batch_mode3_queue
from core import config, get_database, load_tag_mapping, format_size


def _cleanup_on_exit():
    """ç¨‹åºé€€å‡ºæ—¶æ¸…ç†èµ„æº"""
    # å…³é—­æ•°æ®åº“è¿æ¥
    try:
        get_database().close_all_connections()
    except Exception:
        pass

# æ³¨å†Œé€€å‡ºæ¸…ç†é’©å­
atexit.register(_cleanup_on_exit)


def write_failed_records(failed_records):
    """å†™å…¥å¤±è´¥è®°å½•"""
    if not failed_records:
        return
    
    with open(config['path']['failed'], 'a', encoding='utf-8') as f:
        for record in failed_records:
            f.write(f"{record['tag']}|{record['url']}|{record['time']}|"
                   f"{record['id']}|{record['filename']}|{record['tags']}\n")


def write_tag_time(tag_time_dict):
    """
    å†™å…¥downtagæ–‡ä»¶ï¼ˆæ”¯æŒ4ä¸ªå†å²æ—¶é—´æˆ³ï¼‰
    
    æ–°æ ¼å¼: tag {num}: {tag} |time1: {time}|time2: {time}|time3: {time}|time4: {time}
    - time1: æœ€æ–°çš„ä¸‹è½½æ—¶é—´
    - time2-4: å†å²ä¸‹è½½æ—¶é—´ï¼ˆä¾æ¬¡å‘åæ¨ç§»ï¼‰
    - å¦‚æœæ–°çš„time1å’Œå½“å‰time1ç›¸åŒï¼Œä¸æ›´æ–°
    - æŒ‰time1å€’åºæ’åˆ—ï¼ˆæœ€æ–°åœ¨æœ€ä¸‹ï¼Œnumberæœ€å°ï¼‰
    - ä½¿ç”¨ tag-replace.txt å°† replace_tag è½¬æ¢ä¸º original_tag
    """
    if not tag_time_dict:
        return
    
    file_path = config['path']['downtag']
    DEFAULT_TIME = '2000-01-01 00:00:00'
    
    # åŠ è½½ tag æ˜ å°„å…³ç³»ï¼ˆreplace_tag -> original_tagï¼‰
    tag_mapping = load_tag_mapping(reverse=True)
    
    # è½¬æ¢ tag_time_dict ä¸­çš„ replace_tag ä¸º original_tag
    normalized_tag_time = {}
    for tag, time_val in tag_time_dict.items():
        # å¦‚æœæ˜¯ replace_tagï¼Œè½¬æ¢ä¸º original_tag
        original_tag = tag_mapping.get(tag, tag)
        normalized_tag_time[original_tag] = time_val
    
    # è¯»å–ç°æœ‰æ•°æ®ï¼ˆæ”¯æŒæ–°æ—§ä¸¤ç§æ ¼å¼ï¼‰
    tag_times = {}  # {tag_name: [time1, time2, time3, time4]}
    
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if not line or 'time' not in line:
                    continue
                
                # è§£ætagå
                if ': ' not in line:
                    continue
                parts = line.split(': ', 1)
                if len(parts) != 2:
                    continue
 # è§£ææ—¶é—´ï¼ˆæ”¯æŒæ–°æ—§æ ¼å¼ï¼‰
                if '|time1:' in line:
                    # æ–°æ ¼å¼: |time1: xxx|time2: xxx|time3: xxx|time4: xxx
                    # ä¸€æ¬¡æ€§è§£æå®Œæˆ
                    tag_name = parts[1].split('|')[0].strip()
                    time_parts = line.split('|')
                    times = []
                    for part in time_parts:
                        if 'time' in part and ':' in part:
                            time_str = part.split(':', 1)[1].strip()
                            if len(time_str) == 19:  # YYYY-MM-DD HH:MM:SS
                                times.append(time_str)
                    # è¡¥é½åˆ°4ä¸ªæ—¶é—´æˆ³
                    times = (times + [DEFAULT_TIME] * 4)[:4]
                    tag_times[tag_name] = times
                
                elif 'time:' in line:
                    # æ—§æ ¼å¼: time: xxx
                    time_str = line.split('time:', 1)[1].strip()
                    tag_name = parts[1].split('time:')[0].strip()
                    tag_times[tag_name] = [time_str, DEFAULT_TIME, DEFAULT_TIME, DEFAULT_TIME]
    except FileNotFoundError:
        pass  # æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨ç©ºå­—å…¸
    
    # æ›´æ–°æ–°çš„æ—¶é—´
    def parse_time(time_str):
        return datetime.datetime.strptime(time_str, "%Y-%m-%d %H:%M:%S")
    
    for tag, new_time in normalized_tag_time.items():
        if tag not in tag_times:
            # æ–°tagï¼Œåˆå§‹åŒ–
            tag_times[tag] = [new_time, DEFAULT_TIME, DEFAULT_TIME, DEFAULT_TIME]
        else:
            current_times = tag_times[tag]
            # å¦‚æœæ–°æ—¶é—´å’Œtime1ç›¸åŒï¼Œä¸æ›´æ–°
            if new_time != current_times[0]:
                # æ–°æ—¶é—´ä¸åŒï¼Œå‘åæ¨ç§»
                tag_times[tag] = [
                    new_time,           # time1: æ–°æ—¶é—´
                    current_times[0],   # time2: åŸtime1
                    current_times[1],   # time3: åŸtime2
                    current_times[2]    # time4: åŸtime3ï¼ˆåŸtime4ä¸¢å¼ƒï¼‰
                ]
    
    # æŒ‰time1æ’åºï¼ˆå€’åºï¼Œæœ€æ–°åœ¨æœ€ä¸‹ï¼‰
    entries = []
    for tag, times in tag_times.items():
        time1_dt = parse_time(times[0])
        entries.append((tag, time1_dt, times))
    
    entries.sort(key=itemgetter(1), reverse=False)
    
    # å†™å…¥æ–°æ ¼å¼
    content = []
    for idx, (tag, _, times) in enumerate(entries, 1):
        entry_id = len(entries) - idx + 1
        time_str = f"|time1: {times[0]}|time2: {times[1]}|time3: {times[2]}|time4: {times[3]}"
        line = f"tag {entry_id:4}: {tag.ljust(50)} {time_str}\n"
        content.append(line)
    
    with open(file_path, 'w') as f:
        f.writelines(content)



def print_summary_statistics(total_downloaded, total_failed, total_size):
    """
    æ‰“å°æ±‡æ€»ç»Ÿè®¡ä¿¡æ¯
    
    Args:
        total_downloaded: æ€»ä¸‹è½½æˆåŠŸæ•°
        total_failed: æ€»å¤±è´¥æ•°
        total_size: æ€»ä¸‹è½½å¤§å°ï¼ˆå­—èŠ‚ï¼‰
    """
    if total_downloaded == 0 and total_failed == 0:
        print("\n=== æ±‡æ€»ç»Ÿè®¡ ===")
        print("æœ¬æ¬¡è¿è¡Œæœªä¸‹è½½æ–°å›¾ç‰‡")
        return
    
    print("\n" + "="*50)
    print("           æ±‡æ€»ç»Ÿè®¡")
    print("="*50)
    
    # ä½¿ç”¨ format_size ç»Ÿä¸€æ ¼å¼åŒ–
    if total_size > 0:
        total_size_str = format_size(total_size)
        avg_size_str = format_size(total_size // total_downloaded) if total_downloaded > 0 else "0 B"
        print(f"Total size: {total_size_str}  avg size: {avg_size_str}")
    
    print(f"Total download: {total_downloaded} failed: {total_failed}")
    
    if total_downloaded > 0:
        success_rate = (total_downloaded / (total_downloaded + total_failed)) * 100
        print(f"Success rate: {success_rate:.1f}%")
    
    print("="*50 + "\n")


def handle_result(result):
    """
    å¤„ç†å•ä¸ªä¸‹è½½å™¨è¿”å›çš„ç»“æœï¼Œç»Ÿä¸€å†™å…¥æ–‡ä»¶
    
    æ³¨æ„: æ—¥å¿—å’ŒGelbooru/{tag}/tags.txtå·²ç”±çº¿ç¨‹å®æ—¶å†™å…¥ï¼ˆå„è‡ªç‹¬ç«‹æ–‡ä»¶ï¼Œæ— å†²çªï¼‰
    
    Args:
        result: Downloaderè¿”å›çš„å­—å…¸
    """
    db = get_database()
    
    # 1. å†™å…¥å¤±è´¥è®°å½•ï¼ˆåŒæ—¶å†™å…¥txtå’Œæ•°æ®åº“ï¼‰
    if result.get('failed_records'):
        write_failed_records(result['failed_records'])
        # åŒæ—¶å†™å…¥æ•°æ®åº“
        for record in result['failed_records']:
            db.add_failed_download(
                record['tag'], record['url'], record['time'],
                record['id'], record['filename'], record['tags']
            )
    
    # 2. å†™å…¥ä¸‹è½½æˆåŠŸçš„å›¾ç‰‡è®°å½•åˆ°æ•°æ®åº“
    if result.get('downloaded_files'):
        for file_info in result['downloaded_files']:
            db.add_picture(file_info)
    
    # 3. æ›´æ–°è¿›åº¦çŠ¶æ€ï¼ˆä¸­æ–­æ¢å¤ç”¨ï¼‰
    if result.get('status_updates'):
        for tag, update_info in result['status_updates'].items():
            set_tag.update_tagjson(tag, update_info['config'])
    
    # 4. ä¸‹è½½å®Œæˆï¼Œåˆ é™¤æ•°æ®åº“è¿›åº¦è®°å½•
    if result.get('delete_tag'):
        set_tag.delete_tagjson(result['tag'])
    
    # 5. è®¾ç½®ä¸ºå®Œæˆ
    if result.get('set_input_done'):
        set_tag.set_input_done(result['set_input_done'])
    
    # 6. åˆ é™¤å¯åŠ¨æ–‡ä»¶ï¼ˆä¸åˆ é™¤mode=3çš„ç»Ÿä¸€å¯åŠ¨æ–‡ä»¶ï¼‰
    startfile = result.get('remove_startfile')
    if startfile and os.path.exists(startfile):
        # ä¸åˆ é™¤ zzztag.startï¼ˆmode=3çš„ç»Ÿä¸€å¯åŠ¨æ–‡ä»¶ï¼‰
        if not startfile.endswith('zzztag.start'):
            os.remove(startfile)
    
    # 7. æ·»åŠ è¿‡æœŸtag
    if result.get('expire_tags'):
       for expire_tag in result['expire_tags']:
            set_tag.add_expire_tag(expire_tag)
    
    # æ³¨æ„ï¼šç¼©ç•¥å›¾å·²åœ¨downloaderä¸­å¼‚æ­¥æäº¤ï¼Œæ­¤å¤„æ— éœ€å¤„ç†


def _run_batch_queue_mode(mode_name, worker_func, result_handler=None, collect_tag_time=False):
    """
    é€šç”¨æ‰¹é‡é˜Ÿåˆ—å¤„ç†æ¨¡å¼ï¼ˆMode 3/6/7 å…¬å…±é€»è¾‘ï¼‰
    
    Args:
        mode_name: æ¨¡å¼åç§°ï¼ˆç”¨äºæ—¥å¿—ï¼‰
        worker_func: å·¥ä½œå‡½æ•° (task_queue, offset, result_queue) -> result
        result_handler: å¯é€‰çš„ç»“æœå¤„ç†å‡½æ•° (result, stats_collector) -> None
        collect_tag_time: æ˜¯å¦æ”¶é›† tag_timeï¼ˆMode 3éœ€è¦ï¼‰
    
    Returns:
        dict: æ±‡æ€»ç»Ÿè®¡ç»“æœ
    """
    try:
        print(f"\n=== {mode_name} ===\n")
        
        # 1. åˆå§‹åŒ–æ ‡ç­¾åˆ—è¡¨
        set_tag.add_folder_tag()
        set_tag.init_input(1)
        set_tag.add_dead_tag()
        taglist = set_tag.read_tags()
        
        if not taglist:
            print("æ²¡æœ‰å¯å¤„ç†çš„æ ‡ç­¾")
            return {}
        
        print(f"æ€»æ ‡ç­¾æ•°: {len(taglist)}")
        
        # 2. æ£€æŸ¥è¿è¡Œä¸­çš„ä»»åŠ¡ï¼ˆMode 3ä½¿ç”¨ç»Ÿä¸€å¯åŠ¨æ–‡ä»¶ï¼‰
        if mode_name.startswith("Mode 3"):
            unified_start = os.path.join(config['path']['new'], 'zzztag.start')
            if os.path.exists(unified_start):
                print(f"å·²æœ‰Mode 3ä»»åŠ¡è¿è¡Œä¸­ï¼ˆzzztag.startå­˜åœ¨ï¼‰ï¼Œæ— æ³•å¯åŠ¨æ–°ä»»åŠ¡")
                return {}
            # åˆ›å»ºç»Ÿä¸€å¯åŠ¨æ–‡ä»¶
            with open(unified_start, 'w') as f:
                f.write('')
        
        # 3. å›ºå®šä½¿ç”¨6ä¸ªçº¿ç¨‹
        workers = 6
        available = workers
        print(f"å¯ç”¨çº¿ç¨‹: {available}")
        
        # 4. åˆ›å»ºä»»åŠ¡é˜Ÿåˆ—å¹¶å¡«å……
        task_queue = queue.Queue()
        for tag in taglist:
            task_queue.put(tag)
        
        # 5. æ·»åŠ ç»“æŸæ ‡è®°
        for _ in range(available):
            task_queue.put(None)
        
        print(f"ä»»åŠ¡é˜Ÿåˆ—å·²åˆ›å»º: {len(taglist)} ä¸ªtag\n")
        
        # 6. æ•°æ®æ”¶é›†
        stats_collector = {
            'all_tag_time': {},
            'all_done_tags': [],
            'total_downloaded': 0,
            'total_failed': 0,
            'total_size': 0,
            'total_added': 0,
            'total_updated': 0,
            'total_skipped': 0,
            'total_not_found': 0,
        }
        
        start_time = time.time()
        
        # 7. åˆ›å»ºç»“æœé˜Ÿåˆ—ï¼ˆç”¨äºå¢é‡æäº¤ï¼‰
        result_queue = queue.Queue()
        
        # 8. å¯åŠ¨å·¥ä½œçº¿ç¨‹
        with concurrent.futures.ThreadPoolExecutor(max_workers=available) as executor:
            futures = {executor.submit(worker_func, task_queue, i+1, result_queue): i+1 
                      for i in range(available)}
            
            # 9. æ”¶é›†ç»“æœï¼ˆåŒæ—¶å¤„ç†å¢é‡ç»“æœï¼‰
            completed_threads = 0
            while completed_threads < available:
                # å…ˆå¤„ç†å¢é‡ç»“æœ
                while not result_queue.empty():
                    try:
                        intermediate = result_queue.get_nowait()
                        if intermediate.get('type') == 'intermediate':
                            # å¤„ç†å¢é‡æ•°æ®
                            if result_handler:
                                result_handler(intermediate, stats_collector)
                            
                            # æ›´æ–°ç»Ÿè®¡
                            stats_collector['all_tag_time'].update(intermediate.get('tag_time', {}))
                            stats_collector['all_done_tags'].extend(intermediate.get('done_tags', []))
                            stats = intermediate.get('statistics', {})
                            stats_collector['total_downloaded'] += stats.get('downloaded', 0)
                            stats_collector['total_failed'] += stats.get('failed', 0)
                            stats_collector['total_size'] += stats.get('total_size', 0)
                    except queue.Empty:
                        break
                
                # æ£€æŸ¥æ˜¯å¦æœ‰çº¿ç¨‹å®Œæˆ
                done_futures = [f for f in futures if f.done()]
                for future in done_futures:
                    offset = futures[future]
                    try:
                        result = future.result()
                        
                        # åªå¤„ç†æœ€ç»ˆç»“æœ
                        if result.get('type') == 'final':
                            # å¤„ç†æœ€ç»ˆç»“æœ
                            if result_handler:
                                result_handler(result, stats_collector)
                            
                            # æ±‡æ€»ç»Ÿè®¡
                            stats_collector['all_tag_time'].update(result.get('tag_time', {}))
                            stats_collector['all_done_tags'].extend(result.get('done_tags', []))
                            
                            stats = result.get('statistics', {})
                            stats_collector['total_downloaded'] += stats.get('downloaded', 0)
                            stats_collector['total_failed'] += stats.get('failed', 0)
                            stats_collector['total_size'] += stats.get('total_size', 0)
                            stats_collector['total_added'] += stats.get('added', 0)
                            stats_collector['total_updated'] += stats.get('updated', 0)
                            stats_collector['total_skipped'] += stats.get('skipped', 0)
                            stats_collector['total_not_found'] += stats.get('not_found', 0)
                            
                            print(f"\nçº¿ç¨‹ {offset} å·²å®Œæˆ")
                        
                        completed_threads += 1
                        futures.pop(future)
                        
                    except Exception as e:
                        print(f"\nçº¿ç¨‹ {offset} æ‰§è¡Œå‡ºé”™: {e}")
                        import traceback
                        traceback.print_exc()
                        completed_threads += 1
                
                # çŸ­æš‚ä¼‘çœ ï¼Œé¿å…CPUç©ºè½¬
                time.sleep(0.1)
        
        # 10. å¤„ç†å‰©ä½™çš„å¢é‡ç»“æœ
        while not result_queue.empty():
            try:
                intermediate = result_queue.get_nowait()
                if intermediate.get('type') == 'intermediate':
                    if result_handler:
                        result_handler(intermediate, stats_collector)
                    stats_collector['all_tag_time'].update(intermediate.get('tag_time', {}))
                    stats_collector['all_done_tags'].extend(intermediate.get('done_tags', []))
                    stats = intermediate.get('statistics', {})
                    stats_collector['total_downloaded'] += stats.get('downloaded', 0)
                    stats_collector['total_failed'] += stats.get('failed', 0)
                    stats_collector['total_size'] += stats.get('total_size', 0)
            except queue.Empty:
                break
        
        # 11. æ¸…ç©ºä»»åŠ¡é˜Ÿåˆ—ä¸­å¯èƒ½æ®‹ç•™çš„ä»»åŠ¡
        remaining = 0
        while not task_queue.empty():
            try:
                task_queue.get_nowait()
                remaining += 1
            except:
                break
        if remaining > 0:
            print(f"âš  æ¸…ç†äº† {remaining} ä¸ªæœªå¤„ç†çš„é˜Ÿåˆ—ä»»åŠ¡")
        
        # 12. åˆ é™¤ç»Ÿä¸€å¯åŠ¨æ–‡ä»¶ï¼ˆä»…Mode 3ï¼‰
        if mode_name.startswith("Mode 3"):
            unified_start = os.path.join(config['path']['new'], 'zzztag.start')
            if os.path.exists(unified_start):
                try:
                    os.remove(unified_start)
                except Exception as e:
                    print(f"âš ï¸  åˆ é™¤å¯åŠ¨æ–‡ä»¶å¤±è´¥: {e}")
        
        stats_collector['elapsed_minutes'] = (time.time() - start_time) / 60
        stats_collector['total_tags'] = len(taglist)
        
        return stats_collector
        
    finally:
        try:
            get_database().close_all_connections()
        except Exception as e:
            print(f"âš ï¸  å…³é—­æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")



def mode_1():
    """
    æ¨¡å¼1: ä¸‹è½½æ–°æ ‡ç­¾ï¼ˆæ”¯æŒåŠ¨æ€æ·»åŠ  + è‡ªåŠ¨æ¢å¤ä¸­æ–­ï¼‰
    
    ç‰¹ç‚¹ï¼š
    - ä¸‹è½½ status=0ï¼ˆæ–°tagï¼‰å’Œ status=1ï¼ˆä¸­æ–­çš„tagï¼‰
    - å¼‚å¸¸ä¸­æ–­åè‡ªåŠ¨æ¢å¤ï¼Œæ— éœ€æ‰‹åŠ¨åˆ‡æ¢æ¨¡å¼
    - æ¯å®Œæˆä¸€ä¸ªtagåç«‹å³æ ‡è®°done
    - åŠ¨æ€æ‰«æinput.txtï¼Œå®æ—¶æ·»åŠ æ–°tag
    - è‡ªåŠ¨æ¸…ç†å­¤ç«‹çš„ .start æ–‡ä»¶
    """
    from core import get_database
    import os
    import glob
    
    try:
        # åˆå§‹åŒ–
        set_tag.add_folder_tag()
        set_tag.init_input()
        
        tags_config = set_tag.read_tagjson()
        
        # æ¸…ç†å­¤ç«‹çš„ .start æ–‡ä»¶(æ’é™¤mode=3çš„zzztag.start)
        new_path = config['path']['new']
        start_files = glob.glob(os.path.join(new_path, '*.start'))
        
        if start_files:
            # è·å–æ‰€æœ‰æ´»è·ƒçš„ tagï¼ˆè½¬æ¢ä¸ºæ–‡ä»¶åæ ¼å¼ï¼‰
            active_tags = set()
            for tag in tags_config.keys():
                replace_tag = tag.replace('/', '_').replace('\\', '_')
                active_tags.add(f'zzz{replace_tag}.start')
                active_tags.add(f'{tag}.start')
                active_tags.add(f'zzztag{replace_tag}.start')
            
            active_tags.add('zzztag.start')
            
            # æ¸…ç†ä¸å±äºæ´»è·ƒ tag çš„ .start æ–‡ä»¶
            cleaned = 0
            for start_file in start_files:
                basename = os.path.basename(start_file)
                if basename not in active_tags:
                    try:
                        os.remove(start_file)
                        cleaned += 1
                    except Exception as e:
                        print(f"âš ï¸  æ¸…ç†å¯åŠ¨æ–‡ä»¶å¤±è´¥ {basename}: {e}")
            
            if cleaned > 0:
                print(f"âœ“ æ¸…ç†äº† {cleaned} ä¸ªå­¤ç«‹çš„å¯åŠ¨æ–‡ä»¶")
        
        # ç­›é€‰åˆå§‹ä»»åŠ¡ï¼ˆstatus=0 æ–°tag + status=1 ä¸­æ–­tagï¼‰
        initial_tasks = [(tag, info) for tag, info in tags_config.items() 
                        if info['status'] in [0, 1]]
        
        if not initial_tasks:
            print("æ²¡æœ‰éœ€è¦ä¸‹è½½çš„æ ‡ç­¾")
            return
        
        # ç»Ÿè®¡æ–°tagå’Œä¸­æ–­tag
        new_count = sum(1 for _, info in initial_tasks if info['status'] == 0)
        interrupted_count = sum(1 for _, info in initial_tasks if info['status'] == 1)
        
        if interrupted_count > 0:
            print(f"å¼€å§‹ä¸‹è½½ {len(initial_tasks)} ä¸ªæ ‡ç­¾ï¼ˆ{new_count} ä¸ªæ–°æ ‡ç­¾ + {interrupted_count} ä¸ªæ¢å¤ä¸­æ–­ï¼‰")
        else:
            print(f"å¼€å§‹ä¸‹è½½ {new_count} ä¸ªæ–°æ ‡ç­¾")
        
        # å·²å¤„ç†çš„tagé›†åˆï¼ˆé¿å…é‡å¤ï¼‰
        processed_tags = set()
        
        # åˆ›å»ºä»»åŠ¡é˜Ÿåˆ—
        task_queue = queue.Queue()
        for tag, tag_config in initial_tasks:
            task_queue.put((tag, tag_config))
            processed_tags.add(tag)
        
        # ç»Ÿè®¡æ•°æ®
        all_tag_time = {}
        total_downloaded = 0
        total_failed = 0
        total_size = 0
        completed_count = 0
        
        # ä½¿ç”¨6çº¿ç¨‹å¹¶å‘ä¸‹è½½
        with concurrent.futures.ThreadPoolExecutor(max_workers=6) as executor:
            active_futures = {}
            
            # æäº¤åˆå§‹ä»»åŠ¡ï¼ˆæœ€å¤š6ä¸ªï¼‰
            while not task_queue.empty() and len(active_futures) < 6:
                tag, tag_config = task_queue.get()
                future = executor.submit(down_single, tag, tag_config)
                active_futures[future] = tag
            
            # åŠ¨æ€å¤„ç†ä»»åŠ¡
            while active_futures:
                # ç­‰å¾…ä»»ä½•ä¸€ä¸ªä»»åŠ¡å®Œæˆï¼ˆè¶…æ—¶1ç§’ï¼‰
                done_futures = []
                try:
                    for future in concurrent.futures.as_completed(active_futures.keys(), timeout=1):
                        done_futures.append(future)
                except concurrent.futures.TimeoutError:
                    # è¶…æ—¶ï¼šæ²¡æœ‰ä»»åŠ¡å®Œæˆï¼Œç»§ç»­ç­‰å¾…ä¸‹ä¸€è½®
                    # ä½†ä»ç„¶æ£€æŸ¥æ–°tagï¼ˆæ¯ç§’æ‰«æä¸€æ¬¡ï¼‰
                    pass
                
                # å¤„ç†å®Œæˆçš„ä»»åŠ¡
                for future in done_futures:
                    tag = active_futures.pop(future)
                    completed_count += 1
                    
                    try:
                        result = future.result()
                        
                        # ç»Ÿä¸€å¤„ç†ç»“æœï¼ˆä¸»çº¿ç¨‹å†™å…¥ï¼‰
                        handle_result(result)
                        
                        # åˆå¹¶tag_time
                        if result.get('tag_time'):
                            all_tag_time.update(result['tag_time'])
                        
                        # æ”¶é›†ç»Ÿè®¡æ•°æ®
                        stats = result.get('statistics', {})
                        total_downloaded += stats.get('downloaded', 0)
                        total_failed += stats.get('failed', 0)
                        total_size += stats.get('total_size', 0)
                        
                        #è®°å½•tagæ•°
                        db = get_database()
                        today = datetime.datetime.now().strftime("%Y-%m-%d")
                        db.record_daily_query(today, 1)

                        print(f"âœ“ [{completed_count}] {tag} å®Œæˆ")
                        
                    except Exception as e:
                        print(f"âœ— {tag} å‡ºé”™: {e}")
                
                # æ¯æ¬¡å¾ªç¯éƒ½æ£€æŸ¥æ–°tagï¼ˆä¸ç®¡æ˜¯å¦æœ‰ä»»åŠ¡å®Œæˆï¼‰
                new_tags = _scan_new_tags(processed_tags)
                for new_tag, new_config in new_tags:
                    task_queue.put((new_tag, new_config))
                    processed_tags.add(new_tag)
                    print(f"ğŸ†• å‘ç°æ–°æ ‡ç­¾: {new_tag}")
          # è¡¥å……æ–°ä»»åŠ¡åˆ°çº¿ç¨‹æ± ï¼ˆä¿æŒ6ä¸ªå¹¶å‘ï¼‰
                while not task_queue.empty() and len(active_futures) < 6:
                    tag, tag_config = task_queue.get()
                    future = executor.submit(down_single, tag, tag_config)
                    active_futures[future] = tag
            
            # æœ€åç»Ÿä¸€å†™å…¥tag_time
            if all_tag_time:
                write_tag_time(all_tag_time)
            

            # æ‰“å°æ±‡æ€»ç»Ÿè®¡
            print_summary_statistics(total_downloaded, total_failed, total_size)
    
    finally:
        # å…³é—­æ•°æ®åº“è¿æ¥
        try:
            get_database().close_all_connections()
        except Exception as e:
            print(f"âš ï¸  å…³é—­æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")


def _scan_new_tags(processed_tags):
    """
    æ‰«æinput.txtï¼ŒæŸ¥æ‰¾æ–°å¢çš„tag
    
    Args:
        processed_tags: å·²å¤„ç†çš„tagé›†åˆ
    
    Returns:
        list: [(tag, config), ...] æ–°tagåˆ—è¡¨
    """
    new_tags = []
    
    try:
        input_lines = set_tag.readfile(config['path']['input'])
        
        for line in input_lines:
            line = line.strip()
            if not line or line.startswith('TAG') or line.startswith('done '):
                continue
            
            # è§£ææ ‡ç­¾é…ç½®
            parts = line.split()
            if not parts:
                continue
            
            tag_name = parts[0]
            
            # è·³è¿‡å·²å¤„ç†çš„tag
            if tag_name in processed_tags:
                continue
            
            # è¡¥å…¨å‚æ•°ï¼štag [endpage] [start_pic] [end_pic]
            if len(parts) == 1:
                parts.extend(['1', '0', '0'])
            elif len(parts) == 2:
                parts.extend(['0', '0'])
            elif len(parts) == 3:
                parts.append('0')
            
            # æ„å»ºé…ç½®
            tag_config = {
                'startpage': 1,
                'endpage': int(parts[1]),
                'start_pic': int(parts[2]),
                'end_pic': str(parts[3]),
                'status': 0
            }
            
            # æ·»åŠ åˆ°æ•°æ®åº“
            db = get_database()
            db.init_tag_progress(
                tag=tag_name,
                endpage=tag_config['endpage'],
                start_pic=tag_config['start_pic'],
                end_pic=tag_config['end_pic'],
                status=0
            )
            
            new_tags.append((tag_name, tag_config))
    
    except Exception as e:
        print(f"æ‰«ææ–°æ ‡ç­¾å¤±è´¥: {e}")
    
    return new_tags


def mode_3():
    """æ¨¡å¼3: ä¸‹è½½æ‰€æœ‰æ—§æ ‡ç­¾ï¼ˆé˜Ÿåˆ—æ¨¡å¼ - åŠ¨æ€è´Ÿè½½å‡è¡¡ï¼‰"""
    
    stats = _run_batch_queue_mode(
        mode_name="Mode 3: Download All Old Tags",
        worker_func=down_batch_mode3_queue,
        result_handler=lambda r, s: handle_result(r),
        collect_tag_time=True
    )
    
    if not stats:
        return
    
    # Mode 3 ç‰¹æœ‰: ç»Ÿä¸€å†™å…¥ tag_time å’Œ done_tags
    if stats['all_tag_time']:
        write_tag_time(stats['all_tag_time'])
        print(f"\nå·²æ›´æ–° {len(stats['all_tag_time'])} ä¸ªtagåˆ° downtag.txt")
    
    if stats['all_done_tags']:
        set_tag.add_tags(stats['all_done_tags'])
        print(f"å·²æ·»åŠ  {len(stats['all_done_tags'])} ä¸ªtagåˆ° tags.txt")
    
    # è¾“å‡ºæ±‡æ€»æ—¥å¿—
    def print_summary_log(msg):
        current_time = time.strftime('%Y-%m-%d %H:%M:%S')
        print(f"{current_time} | {msg}")
    
    total_downloaded = stats['total_downloaded']
    total_failed = stats['total_failed']
    total_size = stats['total_size']
    
    total_size_str = ""
    if total_downloaded > 0:
        total_size_str = format_size(total_size)
        avg_size_str = format_size(total_size // total_downloaded)
        print_summary_log(f'Total size: {total_size_str}  avg size: {avg_size_str}')
        print_summary_log(f'Total download: {total_downloaded} failed: {total_failed}')
    
    # è¾“å‡º expired tag ç»Ÿè®¡
    nulltag_count = 0
    nulltag_path = config['path'].get('nulltag', config['path'].get('deadtag'))
    if nulltag_path and os.path.exists(nulltag_path):
        with open(nulltag_path, 'r') as fd:
            nulltag_count = sum(1 for _ in fd)
    print_summary_log(f'expired tag: {nulltag_count}')
    
    print_summary_log(f'End tags:{len(stats["all_done_tags"])}')
    print_summary_log('End')
    
    # è¾“å‡ºæ±‡æ€»ç»Ÿè®¡
    print(f"\n{'='*50}")
    print(f"  æ€»è€—æ—¶: {stats['elapsed_minutes']:.1f} åˆ†é’Ÿ")
    print(f"  å·²å¤„ç†: {len(stats['all_done_tags'])}/{stats['total_tags']} ä¸ªtag")
    print(f"  ä¸‹è½½æ•°é‡: {total_downloaded}  å¤±è´¥: {total_failed}")
    if total_downloaded > 0:
        print(f"  ä¸‹è½½å¤§å°: {total_size_str}")
    print(f"{'='*50}\n")


def mode_4():
    """æ¨¡å¼4: æ¸…ç†å·²å®Œæˆè®°å½•"""
    set_tag.del_input_done()
    print("å·²å®Œæˆæ ‡ç­¾æ¸…ç†å®Œæ¯•")


def mode_5(old_tag: str, new_tag: str):
    """
    æ¨¡å¼5: ä¿®æ”¹å›¾ç‰‡çš„tag_name
    
    ç”¨äºå¤„ç†tagåç§°å˜æ›´çš„æƒ…å†µï¼Œä¾‹å¦‚è‰ºæœ¯å®¶æ”¹å
    
    Args:
        old_tag: æ—§çš„tagåç§°
        new_tag: æ–°çš„tagåç§°
    
    æ›´æ–°å†…å®¹:
        - tag_name: old_tag -> new_tag
        - file_path: æ›¿æ¢è·¯å¾„ä¸­çš„old_tagä¸ºnew_tag
        - pic_tags: è¿½åŠ new_tagï¼Œæ—§tagåŠ _oldåç¼€
    """
    from core import get_database
    
    print(f"\n=== Mode 5: ä¿®æ”¹å›¾ç‰‡tag_name ===")
    print(f"  æ—§tag: {old_tag}")
    print(f"  æ–°tag: {new_tag}\n")
    
    db = get_database()
    gelbooru_path = config['path']['Gelbooru']
    
    try:
        # æ£€æŸ¥æ—§tagæ˜¯å¦å­˜åœ¨
        existing = db.get_pictures_by_tag(old_tag)
        if not existing:
            print(f"âŒ æ•°æ®åº“ä¸­æ²¡æœ‰æ‰¾åˆ°tag: {old_tag}")
            return
        
        print(f"æ‰¾åˆ° {len(existing)} å¼ å›¾ç‰‡éœ€è¦æ›´æ–°")
        
        # æ‰§è¡Œæ›´æ–°
        updated_count = db.update_picture_tag_name(old_tag, new_tag, gelbooru_path)
        
        print(f"âœ“ æˆåŠŸæ›´æ–° {updated_count} æ¡è®°å½•")
        print(f"\næ³¨æ„: è¯·æ‰‹åŠ¨å°†æ–‡ä»¶å¤¹ä» {old_tag} é‡å‘½åä¸º {new_tag}")
        print(f"  è·¯å¾„: {gelbooru_path}\\{old_tag} -> {gelbooru_path}\\{new_tag}")
        
    except Exception as e:
        print(f"âŒ æ›´æ–°å¤±è´¥: {e}")
    finally:
        try:
            db.close_all_connections()
        except Exception:
            pass


def mode_6():
    """æ¨¡å¼6: æ›´æ–°å›¾ç‰‡ä¿¡æ¯ï¼ˆMode 3å˜ç§ï¼Œä¸ä¸‹è½½åªæ›´æ–°DBï¼‰"""
    from downloader import update_batch_mode6_queue
    
    stats = _run_batch_queue_mode(
        mode_name="Mode 6: æ›´æ–°å›¾ç‰‡ä¿¡æ¯",
        worker_func=update_batch_mode6_queue
    )
    
    if not stats:
        return
    
    # è¾“å‡ºæ±‡æ€»ç»Ÿè®¡
    print(f"\n{'='*50}")
    print(f"  æ€»è€—æ—¶: {stats['elapsed_minutes']:.1f} åˆ†é’Ÿ")
    print(f"  æ–°å¢è®°å½•: {stats['total_added']}")
    print(f"  æ›´æ–°è®°å½•: {stats['total_updated']}")
    print(f"  è·³è¿‡(æœ¬åœ°æ— æ–‡ä»¶): {stats['total_skipped']}")
    print(f"{'='*50}\n")


def mode_7():
    """æ¨¡å¼7: ä»æœ¬åœ°tags.txtå¯¼å…¥å›¾ç‰‡ä¿¡æ¯åˆ°DBï¼ˆä¸è”ç½‘ï¼‰"""
    from downloader import update_batch_mode7_queue
    
    stats = _run_batch_queue_mode(
        mode_name="Mode 7: ä»æœ¬åœ°tags.txtå¯¼å…¥å›¾ç‰‡ä¿¡æ¯",
        worker_func=update_batch_mode7_queue
    )
    
    if not stats:
        return
    
    # è¾“å‡ºæ±‡æ€»ç»Ÿè®¡
    print(f"\n{'='*50}")
    print(f"  æ€»è€—æ—¶: {stats['elapsed_minutes']:.1f} åˆ†é’Ÿ")
    print(f"  æ–°å¢è®°å½•: {stats['total_added']}")
    print(f"  è·³è¿‡(å·²å­˜åœ¨): {stats['total_skipped']}")
    print(f"  æœªæ‰¾åˆ°(æ— tags.txt): {stats['total_not_found']}")
    print(f"{'='*50}\n")


def mode_0(tag: str):
    """
    è°ƒè¯•æ¨¡å¼0: åˆ†æä¸‹è½½æµç¨‹é—®é¢˜
    
    åŠŸèƒ½:
    - ä¸åˆ›å»ºç›®å½•å’Œä¸‹è½½æ–‡ä»¶
    - è·å–ç¬¬ä¸€é¡µçš„åˆ—è¡¨é¡µé¢ä¿¡æ¯
    - è®°å½•é¡µé¢URLã€HTMLå†…å®¹ç‰‡æ®µã€åŒ¹é…æ¨¡å¼å’Œç»“æœåˆ°check.log
    - å¯¹ç¬¬ä¸€ä¸ªå›¾ç‰‡é¡µé¢è¿›è¡Œè¯¦ç»†åˆ†æ
    
    ä½¿ç”¨æ–¹æ³•: python main.py 0 {tag}
    
    Args:
        tag: è¦è°ƒè¯•çš„æ ‡ç­¾å
    """
    import requests
    from bs4 import BeautifulSoup
    import re
    import json
    import os
    import time
    from urllib.parse import urljoin
    
    print(f"\n=== Mode 0: Debug Analysis for tag '{tag}' ===\n")
    
    # åˆ›å»ºcheck.logæ–‡ä»¶
    log_path = os.path.join(os.path.dirname(__file__), 'check.log')
    
    with open(log_path, 'w', encoding='utf-8') as logf:
        def log(msg):
            """åŒæ—¶æ‰“å°åˆ°æ§åˆ¶å°å’Œå†™å…¥æ—¥å¿—æ–‡ä»¶"""
            print(msg)
            logf.write(msg + '\n')
        
        # è®°å½•å¼€å§‹æ—¶é—´
        start_time = time.strftime('%Y-%m-%d %H:%M:%S')
        log(f"[{start_time}] å¼€å§‹è°ƒè¯•æ ‡ç­¾: {tag}")
        log("=" * 60)
        
        # 1. æ„é€ åŸºç¡€URLå’Œé…ç½®
        base_url = config['url']
        headers = config['headers']
        
        log(f"åŸºç¡€URL: {base_url}")
        log(f"Headers: {json.dumps(headers, indent=2, ensure_ascii=False)}")
        log("")
        
        # 2. æµ‹è¯•ç¬¬ä¸€é¡µï¼ˆpid=0ï¼‰
        page_url = f"{base_url}{tag}"
        log(f"==== ç¬¬ 1 é¡µ ====")
        log(f"URL: {page_url}")
        log("-" * 40)
        
        # è·å–é¡µé¢å†…å®¹
        try:
            response = requests.get(page_url, headers=headers, timeout=15)
            response.raise_for_status()
            html_content = response.text
            
            log(f"âœ“ è¯·æ±‚æˆåŠŸï¼ŒçŠ¶æ€ç : {response.status_code}")
            log(f"âœ“ é¡µé¢å¤§å°: {len(html_content)} å­—ç¬¦")
            
            # ä¿å­˜å®Œæ•´çš„HTMLå†…å®¹åˆ°æ—¥å¿—
            log("\n--- å®Œæ•´HTMLå†…å®¹ ---")
            log(html_content[:2000])  # åªè®°å½•å‰2000å­—ç¬¦é¿å…æ–‡ä»¶è¿‡å¤§
            log("--- HTMLå†…å®¹ç»“æŸ ---\n")
            
            # è§£æHTML
            soup = BeautifulSoup(html_content, 'html.parser')
            
            # æµ‹è¯•å›¾ç‰‡åˆ—è¡¨æå–
            log("å°è¯•æå–å›¾ç‰‡åˆ—è¡¨:")
            
            # æ–¹æ³•1: ä½¿ç”¨get_image_listæ–¹æ³•é€»è¾‘
            try:
                image_urls_method1 = []
                articles = soup.find_all('article')
                for article in articles:
                    links = article.find_all('a')
                    if links:
                        href = links[0].get('href', '')
                        if href:
                            image_urls_method1.append(href)
            
                log(f"æ–¹æ³•1 (find_all article): æ‰¾åˆ° {len(image_urls_method1)} ä¸ªå›¾ç‰‡é“¾æ¥")
                for i, url in enumerate(image_urls_method1[:3]):  # åªæ˜¾ç¤ºå‰3ä¸ª
                    log(f"  {i+1}. {url}")
            except Exception as e:
                log(f"æ–¹æ³•1å¤±è´¥: {e}")
            
            # æ–¹æ³•2: ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…
            try:
                # ä¿®æ”¹æ­£åˆ™è¡¨è¾¾å¼ä»¥åŒ¹é…HTMLå®ä½“ç¼–ç çš„&amp;ç¬¦å·
                pattern = re.compile(r'href=["\'](index\.php\?page=post&(?:amp;)?s=view&(?:amp;)?id=\d+&(?:amp;)?tags=[^"\']*)["\']')
                matches = pattern.findall(html_content)
                unique_matches = list(set(matches))  # å»é‡
                
                log(f"\næ–¹æ³•2 (æ­£åˆ™è¡¨è¾¾å¼): æ‰¾åˆ° {len(unique_matches)} ä¸ªå”¯ä¸€é“¾æ¥")
                for i, match in enumerate(unique_matches[:3]):
                    full_url = urljoin(base_url, match)
                    log(f"  {i+1}. {full_url}")
                    
                log(f"\næ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼: {pattern.pattern}")
            except Exception as e:
                log(f"æ–¹æ³•2å¤±è´¥: {e}")

            # 3. å¯¹ç¬¬ä¸€ä¸ªå›¾ç‰‡è¿›è¡Œè¯¦ç»†åˆ†æ
            if unique_matches:
                img_path = unique_matches[0]
                img_url = urljoin(base_url, img_path)
                log(f"\n==== åˆ†æç¬¬ä¸€ä¸ªå›¾ç‰‡: {img_url} ====")
                
                try:
                    img_response = requests.get(img_url, headers=headers, timeout=15)
                    img_response.raise_for_status()
                    img_html = img_response.text
                    img_soup = BeautifulSoup(img_html, 'html.parser')
                    
                    log(f"âœ“ å›¾ç‰‡é¡µé¢è·å–æˆåŠŸï¼Œå¤§å°: {len(img_html)} å­—ç¬¦")
                    
                    # æå–å›¾ç‰‡ID
                    img_id_match = re.search(r'id=(\d+)', img_path)
                    img_id = img_id_match.group(1) if img_id_match else "unknown"
                    log(f"å›¾ç‰‡ID: {img_id}")
                    
                    # æå–æ ‡ç­¾
                    try:
                        tags_found = []
                        # æŸ¥æ‰¾æ ‡ç­¾div
                        tag_elements = img_soup.find_all('li', class_=re.compile(r'tag-type-'))
                        for tag_elem in tag_elements:
                            tag_link = tag_elem.find('a', class_='search-tag')
                            if tag_link:
                                tags_found.append(tag_link.text.strip())
                    
                        # ä»æ ‡é¢˜æå–
                        if img_soup.title and img_soup.title.string:
                            title_part = img_soup.title.string.split('- Image View -')[0].strip()
                            if title_part and '|' in title_part:
                                title_tags = [t.strip() for t in title_part.split('|')]
                                tags_found.extend(title_tags)
                    
                        # å»é‡
                        unique_tags = list(dict.fromkeys(tags_found))[:5]
                        log(f"æ‰¾åˆ°æ ‡ç­¾ ({len(unique_tags)}ä¸ª): {', '.join(unique_tags)}")
                    except Exception as e:
                        log(f"æ ‡ç­¾æå–å¤±è´¥: {e}")
                    
                    # æå–ä¸‹è½½é“¾æ¥
                    try:
                        download_links = []
                        # æŸ¥æ‰¾highresé“¾æ¥
                        highres_link = img_soup.find('a', id='highres')
                        if highres_link and highres_link.get('href'):
                            download_links.append(('highres', highres_link['href']))
                    
                        # æŸ¥æ‰¾og:image
                        og_image = img_soup.find('meta', property='og:image')
                        if og_image and og_image.get('content'):
                            download_links.append(('og:image', og_image['content']))
                    
                        log(f"æ‰¾åˆ°ä¸‹è½½é“¾æ¥ ({len(download_links)}ä¸ª):")
                        for link_type, link_url in download_links:
                            log(f"  {link_type}: {link_url}")
                            
                    except Exception as e:
                        log(f"ä¸‹è½½é“¾æ¥æå–å¤±è´¥: {e}")
                    
                except Exception as e:
                    log(f"âœ— å›¾ç‰‡é¡µé¢è·å–å¤±è´¥: {e}")
            else:
                log("æœªæ‰¾åˆ°ä»»ä½•å›¾ç‰‡é“¾æ¥")
            
        except Exception as e:
            log(f"âœ— é¡µé¢è¯·æ±‚å¤±è´¥: {e}")
        
        # 4. æ€»ç»“
        end_time = time.strftime('%Y-%m-%d %H:%M:%S')
        log(f"\n[{end_time}] è°ƒè¯•å®Œæˆ")
        log("=" * 60)
    
    print(f"\nâœ“ è°ƒè¯•æ—¥å¿—å·²ä¿å­˜åˆ°: {log_path}")
    print("è¯·æ£€æŸ¥check.logæ–‡ä»¶ä»¥åˆ†æé—®é¢˜æ‰€åœ¨")


def main():
    """ä¸»å‡½æ•°"""
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ–¹æ³•: python main.py [0|1|3|4|5|6|7]")
        print("  0 - è°ƒè¯•æ¨¡å¼ï¼ˆåˆ†æä¸‹è½½é—®é¢˜ï¼Œä¸ä¸‹è½½æ–‡ä»¶ï¼‰")
        print("  1 - ä¸‹è½½æ–°æ ‡ç­¾ï¼ˆè‡ªåŠ¨æ¢å¤ä¸­æ–­ï¼‰")
        print("  3 - ä¸‹è½½æ‰€æœ‰æ—§æ ‡ç­¾")
        print("  4 - æ¸…ç†å·²å®Œæˆè®°å½•")
        print("  5 old_tag new_tag - ä¿®æ”¹å›¾ç‰‡tag_name")
        print("  6 - æ›´æ–°å›¾ç‰‡ä¿¡æ¯ï¼ˆä¸ä¸‹è½½ï¼Œè”ç½‘è·å–ï¼‰")
        print("  7 - ä»æœ¬åœ°tags.txtå¯¼å…¥å›¾ç‰‡ä¿¡æ¯ï¼ˆä¸è”ç½‘ï¼‰")
        return
    
    mode = sys.argv[1]
    
    try:
        if mode == '0':
            if len(sys.argv) < 3:
                print("Mode 0 éœ€è¦æŒ‡å®šæ ‡ç­¾å: python main.py 0 {tag}")
                return
            mode_0(sys.argv[2])
        elif mode == '1':
            mode_1()
        elif mode == '3':
            mode_3()
        elif mode == '4':
            mode_4()
        elif mode == '5':
            if len(sys.argv) < 4:
                print("Mode 5 éœ€è¦ä¸¤ä¸ªå‚æ•°: python main.py 5 old_tag new_tag")
                return
            mode_5(sys.argv[2], sys.argv[3])
        elif mode == '6':
            mode_6()
        elif mode == '7':
            mode_7()
        else:
            print(f"æœªçŸ¥æ¨¡å¼: {mode}")
            print("å¯ç”¨æ¨¡å¼: 0, 1, 3, 4, 5, 6, 7")
    finally:
        print("\næ‰€æœ‰ä»»åŠ¡å®Œæˆ")


if __name__ == '__main__':
    main()
